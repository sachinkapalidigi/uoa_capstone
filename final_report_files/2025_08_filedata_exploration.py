# -*- coding: utf-8 -*-
"""2025_08_FileData_Exploration.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OOUepsEbSho1J-1CGch2C1PCzy2nApdJ

# Init
Set access to the relevant functions
"""

import pandas as pd
import numpy as np
import json

#Connect to drive
from google.colab import drive
drive.mount('/content/drive')

#path to drive
path = '/content/drive/MyDrive/Capstone/MICoL_data' #FP's Path

"""# Files to explore

1. PubMed Input - Preprocessed files to input to the model
2. PubMed - Original datasets for preprocessing
3. PubMed Output - Fine-tuned model. No need to further explore.

## PubMed Input
These are the documents the code uses to train and evaluate the model. The one that needs the most attention is the train.txt.

This is the file that will need the expansion based on what we suggested.

### Enhanced Training
"""

enhanced_train = pd.read_csv("/content/drive/MyDrive/Capstone/MICoL_data/Test/train_C.txt", delimiter="\t", header=None, names=['Pair', 'Doc1', 'Doc2'])
enhanced_train.describe(include='all')

enhanced_train.info()

enhanced_train.tail(5)

"""### Enhanced Dev"""

enhanced_dev = pd.read_csv("/content/drive/MyDrive/Capstone/MICoL_data/Test/dev_C.txt", delimiter="\t", header=None, names=['Pair', 'Doc1', 'Doc2'])
enhanced_dev.describe(include='all')

enhanced_dev.tail(5)

"""### Train.txt

File created to train the model. This is the document to be expanded with label definitions.
"""

# Explore the train.txt file

'''The train.txt file includes 100,000 document pair for training. Document do show repetitive sometimes'''

train = pd.read_csv(path +"/PubMed_input/train.txt", delimiter="\t", header=None, names=['Pair', 'Doc1', 'Doc2'])
train.describe(include='all')

train.head(10)

"""### dev.txt
Use to evaluate the model during the training stage.
"""

#Explore dev.txt

dev = pd.read_csv(path +"/PubMed_input/dev.txt", delimiter="\t", header=None, names=['Pair', 'Doc1', 'Doc2'])
dev.describe(include='all')

dev.head()

"""### test.txt
This document is used to check the outputs of the models with the correct responses. Do not touch.
"""

test = pd.read_csv(path +"/PubMed_input/test.txt", delimiter="\t", header=None, names=['Is Correct', 'Doc', 'Correct Label'])
test.describe(include='all')

test.head(10)

"""### Dataset.txt

This is the original file that gets distributed into the dev and training set
"""

dataset = pd.read_csv(path +"/PubMed_input/dataset.txt", delimiter="\t", header=None, names=['Pair', 'Doc1', 'Doc2'])
test.describe(include='all')

dataset.head(10)

"""## PubMed
Raw files dataset

### Candidates.json
"""

candidates = pd.read_json(path +"/PubMed/PubMed_candidates.json", lines=True)

candidates.info()

candidates.head(10)

"""### PubMed_label"""

labels = pd.read_json(path +"/PubMed/PubMed_label.json", lines=True)

labels.info()

labels.describe(include='all')

labels.head(10)

"""### PubMed_test
Contain all information from papers for testing
"""

pubMed_Test = pd.read_json(path +"/PubMed/PubMed_test.json", lines=True)
pubMed_Test.info()

pubMed_Test.head(10)

"""### PubMed_train

"""

pubMed_Train = pd.read_json(path +"/PubMed/PubMed_train.json", lines=True)
pubMed_Train.info()

pubMed_Train.head(10)

"""# Mesh

### Mesh Hierarchy Load
"""

def load_mesh():
  '''Load mesh hierarchy based on the original architecture'''

  with open(path +"/PubMed/mesh_hierarchy_v2.json", 'r') as f:
      data = json.load(f)

  data = data['descriptor_details']

  mesh = []
  for line in data.items():
      mesh.append(line[1])

  mesh = pd.DataFrame(mesh)
  return mesh

mesh = load_mesh()

mesh.describe(include='all')

mesh.info()

mesh.head(10)

"""### Mesh Post Processing"""

def mesh_post_processing(mesh):

  #Create dataset with only mesh labels
  mesh_labels = mesh[['mesh_id','name','definition']]
  mesh_labels['concat'] = mesh['name'] +". "+ mesh['definition']

  #create datset with only ids and tree hierarchys
  df = mesh[['mesh_id','tree_numbers']]
  mesh_hierarchy = df.explode('tree_numbers')
  mesh_hierarchy = mesh_hierarchy.reset_index(drop=True)

  #create dataset with hierarchy. Make copy
  df_hierarchy = mesh_hierarchy.copy()
  mesh_hierarchy_1 = mesh_hierarchy.copy()

  #Create data hierarchy by spliting and accessing the correct level
  newColumns = ["0","1","2","3","4","5","6","7","8","9","10","11","12"]
  mesh_hierarchy_1[newColumns] = mesh_hierarchy['tree_numbers'].str.split('.', expand=True)


  # Split into components
  split_df = mesh_hierarchy['tree_numbers'].str.split('.', expand=True)
  split_df.columns = [f'level_{i+1}' for i in range(split_df.shape[1])]

  # Create cumulative hierarchy
  for i in range(len(split_df.columns)):
      col_name = f'hierarchy_level_{i+1}'
      df_hierarchy[col_name] = split_df.iloc[:, :i+1].apply(
          lambda x: '.'.join(x.dropna().astype(str)), axis=1
      )

  return mesh_labels, mesh_hierarchy_1, df_hierarchy

mesh_labels, mesh_hierarchy1, df_hierarchy = mesh_post_processing(mesh)

mesh_labels.head(5)

mesh_hierarchy1.info()

mesh_hierarchy1.head(5)

df_hierarchy.head(10)

df_hierarchy.info()

df_hierarchy.to_csv(path + "/df_hierarchy.csv")

"""# Dataset Development

After exploration, code development to integration to main code.

## Function definitions

### Load datasets
"""

#load mesh file
def load_mesh():
  '''Load mesh hierarchy based on the original architecture'''

  with open(path +"/PubMed/mesh_hierarchy_v2.json", 'r') as f:
      data = json.load(f)

  data = data['descriptor_details']

  mesh = []
  for line in data.items():
      mesh.append(line[1])

  mesh = pd.DataFrame(mesh)
  return mesh

#Get all labels that are not in the original training or testing set
def get_new_labels_ids(labels, mesh):
  new_labels = mesh[~mesh['mesh_id'].isin(labels['label'])]

  return new_labels


# Create splited datasets for label definitions and label hierarchy
def mesh_post_processing(mesh):

  #Create dataset with only mesh labels
  mesh_labels = mesh[['mesh_id','name','definition']]
  mesh_labels['concat'] = mesh['name'] +". "+ mesh['definition']

  #create datset with only ids and tree hierarchys
  df = mesh[['mesh_id','tree_numbers']]
  mesh_hierarchy = df.explode('tree_numbers')
  mesh_hierarchy = mesh_hierarchy.reset_index(drop=True)

  #create dataset with hierarchy. Make copy
  mesh_hierarchy = mesh_hierarchy.copy()

  #Create data hierarchy by spliting and accessing the correct level
  newColumns = ["0","1","2","3","4","5","6","7","8","9","10","11","12"]
  mesh_hierarchy[newColumns] = mesh_hierarchy['tree_numbers'].str.split('.', expand=True)
  mesh_hierarchy['tree'] = mesh_hierarchy['0'].str.replace(r'[^A-Za-z]', '', regex=True)

  return mesh_labels, mesh_hierarchy

"""### Negative pairs creation"""

# Negative Pair - or just get random from a list of labels
def get_random_pair(id, labels):

  random_id = np.random.choice(labels["mesh_id"])

  #print(random_id) #debugging line
  while id == random_id:
    random_id = np.random.choice(labels["mesh_id"])

    if labels["mesh_id"].size == 1:
      random_id = -1 #to break from the while loop
      return None, None

  #return id and definition
  return random_id , labels[labels["mesh_id"] == random_id]

#Get tree letter
def get_tree(id, mesh_hierarchy):
  tree = mesh_hierarchy[mesh_hierarchy["mesh_id"] == id]["tree"].values[0]
  return tree

#Get full tree details
def get_full_tree(id, mesh_hierarchy):
  full_tree = mesh_hierarchy[mesh_hierarchy["mesh_id"] == id]["tree_numbers"].values[0]
  return full_tree

# Negative Pair - Random Sample Different Three
def get_random_diff_tree(id, mesh_hierarchy, mesh_labels):

  tree = get_tree(id, mesh_hierarchy)

  shortlisted_ids = mesh_hierarchy[mesh_hierarchy["tree"] != tree]
  shortlisted_labels = mesh_labels[mesh_labels["mesh_id"].isin(shortlisted_ids["mesh_id"])]

  #get random from shotlisted
  random_id, details = get_random_pair(id, shortlisted_labels)

  return random_id, details

"""### Positive pair creation

"""

# Create parent-child relationship
def get_parent_child_pair(tree_id, mesh_hierarchy, mesh_labels):

  #Branch does not have parent
  if pd.isna(tree_id):
    return None, None

  id = mesh_hierarchy[mesh_hierarchy["tree_numbers"] == tree_id]["mesh_id"].values[0]
  parent_tree = tree_id.rsplit('.', 1)[0]       # Get parent tree

  not_parent = True

  # Loop to check for parent upper in the hierarchy
  while(not_parent):
    #print("WHILE")

    #print(parent_tree) #Debugging line

    #Get shortlisted ids for labels that have the same parent tree
    shortlisted_ids = mesh_hierarchy[mesh_hierarchy["tree_numbers"] == parent_tree]
    shortlisted_labels = mesh_labels[mesh_labels["mesh_id"].isin(shortlisted_ids["mesh_id"])]

    #print(shortlisted_labels) #debugging line
    #print(shortlisted_ids) #debugging line

    #In case there are many parents for the same three, which should not be the case
    #print("Main test: ", parent_tree) #debugging line

    if shortlisted_labels.empty:
      #(parent_tree)  # debugging
      if parent_tree.find(".") == -1:
        #print("Parent not found for: ", id, "\n")
        not_parent = False
        return None, None

      parent_tree = parent_tree.rsplit('.', 1)[0]
      #print("Additional split") #debugging

    else:
      #print("Parent found") #debugging
      #print(id)
      #print(shortlisted_labels)
      random_id, details = get_random_pair(id, shortlisted_labels)
      not_parent = False
      #print("Parent found - break") #debugging

  return random_id, details

# Get siblings pair
def get_siblings_pair(tree_id, mesh_hierarchy, mesh_labels):

  #Branch does not have parent
  if pd.isna(tree_id):
    return None, None

  #get Id for intended label
  id = mesh_hierarchy[mesh_hierarchy["tree_numbers"] == tree_id]["mesh_id"].values[0]
  parent_tree = tree_id.rsplit('.', 1)[0] + "."

  #Get shortlisted ids for labels that have the same parent tree
  shortlisted_ids = mesh_hierarchy[mesh_hierarchy["tree_numbers"].str.contains(parent_tree, na=False)]
  shortlisted_labels = mesh_labels[mesh_labels["mesh_id"].isin(shortlisted_ids["mesh_id"])]


  #In case there are many parents for the same three, which should not be the case
  if shortlisted_labels.empty:
    return None, None

  else:
    random_id, details = get_random_pair(id, shortlisted_labels)

  return random_id, details

"""### Create support files"""

# Create positive pairs files
def create_model_pairs(pair_type, mesh_hierarchy, mesh_labels):

  tempdoc = []
  column = "concat"

  match pair_type:

    # Positive Pair: parent-child relationship, Negative Pair: random sample
    case "A":

      print("Pairing Model A")

      for i, row in mesh_hierarchy.iterrows():

        # To check where in the progress we are
        if i % 1000 == 0:
          print("Evaluating Item: ", i, "/", len(mesh_hierarchy))

        id = row["mesh_id"]
        tree_id = row["tree_numbers"]

        #get main doc
        doc = mesh_labels[mesh_labels["mesh_id"] == id][column].values[0]

        #positive pair
        id, temp = get_parent_child_pair(tree_id, mesh_hierarchy, mesh_labels)
        if id is None:
          continue
        pos = temp[column].values[0]

        #negative pair
        id, temp = get_random_pair(id, mesh_labels)
        if id is None:
          continue
        neg = temp[column].values[0]

        pos_pair = [1, doc, pos]
        neg_pair = [0, doc, neg]

        #check that we are not adding any duplicative information
        if pos_pair in tempdoc:
          continue

        tempdoc.append(pos_pair)
        tempdoc.append(neg_pair)

      return pd.DataFrame(tempdoc, columns=['pair', 'doc1', 'doc2'])

    # Positive Pair: parent-child relationship, Negative Pair: different root
    case "B":

      print("Pairing Model B")

      for i, row in mesh_hierarchy.iterrows():

        # To check where in the progress we are
        if i % 1000 == 0:
          print("Evaluating Item: ", i, "/", len(mesh_hierarchy))

        id = row["mesh_id"]
        tree_id = row["tree_numbers"]

        #get main doc
        doc = mesh_labels[mesh_labels["mesh_id"] == id][column].values[0]

        #positive pair
        id, temp = get_parent_child_pair(tree_id, mesh_hierarchy, mesh_labels)
        if id is None:
          continue
        pos = temp[column].values[0]

        #negative pair
        id, temp = get_random_diff_tree(id, mesh_hierarchy, mesh_labels)
        if id is None:
          continue
        neg = temp[column].values[0]

        pos_pair = [1, doc, pos]
        neg_pair = [0, doc, neg]

        #check that we are not adding any duplicative information
        if pos_pair in tempdoc:
          continue

        tempdoc.append(pos_pair)
        tempdoc.append(neg_pair)

      return pd.DataFrame(tempdoc, columns=['pair', 'doc1', 'doc2'])

    # Positive Pair: Sibling relationship, Negative Pair: random sample
    case "C":

      print("Pairing Model C")

      for i, row in mesh_hierarchy.iterrows():

        # To check where in the progress we are
        if i % 1000 == 0:
          print("Evaluating Item: ", i, "/", len(mesh_hierarchy))

        id = row["mesh_id"]
        tree_id = row["tree_numbers"]

        #get main doc
        doc = mesh_labels[mesh_labels["mesh_id"] == id][column].values[0]

        #positive pair
        id, temp = get_siblings_pair(tree_id, mesh_hierarchy, mesh_labels)
        if id is None:
          continue
        pos = temp[column].values[0]

        #negative pair
        id, temp = get_random_pair(id, mesh_labels)
        if id is None:
          continue
        neg = temp[column].values[0]

        pos_pair = [1, doc, pos]
        neg_pair = [0, doc, neg]

        #check that we are not adding any duplicative information
        if pos_pair in tempdoc:
          continue

        tempdoc.append(pos_pair)
        tempdoc.append(neg_pair)

      return pd.DataFrame(tempdoc, columns=['pair', 'doc1', 'doc2'])

    # Positive Pair: Sibling relationship, Negative Pair: different root
    case "D":

      print("Pairing Model D")

      for i, row in mesh_hierarchy.iterrows():

        # To check where in the progress we are
        if i % 1000 == 0:
          print("Evaluating Item: ", i, "/", len(mesh_hierarchy))

        id = row["mesh_id"]
        tree_id = row["tree_numbers"]

        #get main doc
        doc = mesh_labels[mesh_labels["mesh_id"] == id][column].values[0]

        #positive pair
        id, temp = get_siblings_pair(tree_id, mesh_hierarchy, mesh_labels)
        if id is None:
          continue
        pos = temp[column].values[0]

        #negative pair
        id, temp = get_random_diff_tree(id, mesh_hierarchy, mesh_labels)
        if id is None:
          continue
        neg = temp[column].values[0]

        pos_pair = [1, doc, pos]
        neg_pair = [0, doc, neg]

        #check that we are not adding any duplicative information
        if pos_pair in tempdoc:
          continue

        tempdoc.append(pos_pair)
        tempdoc.append(neg_pair)

      return pd.DataFrame(tempdoc, columns=['pair', 'doc1', 'doc2'])

    case _:
      print("Error! Wrong pairing type")

      return None

# clean file and write into csv
def clean_file(df, path, model):

  #decided not to clean to keep the training set balanced.

  #df_clean = df.drop_duplicates()
  #df_clean = df_clean.dropna().reset_index(drop=True)

  #Store file in path
  df.to_csv(path + "/enhanced_" + model+".csv", index=False, header= False, sep="\t")

  return df

"""## Main

### Loading datasets and creating working datasets

The filtered MeSH has 12993 unique new ids.

When creating the mesh_hierachy view. I can generated 23363 new positive and negative pairs for model to train the model. That means that the training set gets expanded by about __20%__.
"""

#### MAIN ####

# load datasets
labels = pd.read_json(path +"/PubMed/PubMed_label.json", lines=True)
mesh = load_mesh()

#get filtered dataset with unique ids
f_mesh = get_new_labels_ids(labels, mesh)

#create separate datasets needed
mesh_labels, mesh_hierarchy = mesh_post_processing(f_mesh)

"""Next step is to generate a for loop for every label that generates the different pairs in the document style format"""

# Generate Model D
pair_type = "D"

#create samples and store dataset enhancements
temp = create_model_pairs(pair_type, mesh_hierarchy, mesh_labels)
B = clean_file(temp, path, pair_type)

#visualize first sample
print(B.info())
B.head()

# Generate Model C
pair_type = "C"

#create samples and store dataset enhancements
temp = create_model_pairs(pair_type, mesh_hierarchy, mesh_labels)
B = clean_file(temp, path, pair_type)

#visualize first sample
print(B.info())
B.head()

# Generate Model B
pair_type = "B"

#create samples and store dataset enhancements
temp = create_model_pairs(pair_type, mesh_hierarchy, mesh_labels)
B = clean_file(temp, path, pair_type)

#visualize first sample
print(B.info())
B.head()

# Generate Model A
pair_type = "A"

#create samples and store dataset enhancements
temp = create_model_pairs(pair_type, mesh_hierarchy, mesh_labels)
A = clean_file(temp, path, pair_type)

#visualize first sample
print(A.info())
A.head()

"""### Testing"""

## Test Example.

pair_type = "A"

#create samples and store models
temp = create_model_pairs(pair_type, mesh_hierarchy, mesh_labels)
A = clean_file(temp, path, pair_type)
A.head(20)



'''
#get random ids
id, df = get_siblings_pair("D02.540.576.625.125", mesh_hierarchy, mesh_labels)
print(id)
df.head(1)
'''

mesh_hierarchy.describe(include='all')

mesh_hierarchy.head()

mesh_labels.head()

